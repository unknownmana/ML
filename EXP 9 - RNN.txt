
import tensorflow as tf
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Embedding,SimpleRNN,Dense


# In[70]:


num_words=1000
(x_train,y_train),(x_test,y_test) = imdb.load_data(num_words=num_words)

max_len = 500
x_train = pad_sequences(x_train,maxlen=max_len)
x_test = pad_sequences(x_test,maxlen=max_len)


# In[72]:


model = tf.keras.models.Sequential([
    Embedding(input_dim=num_words,output_dim=64,input_length=max_len),
    SimpleRNN(64,return_sequences=False),
    Dense(1,activation='sigmoid')
])


# In[73]:


model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])


# In[74]:


model.fit(x_train,y_train,epochs=5,batch_size=32,validation_split=.2)


# In[75]:


test_loss,test_acc = model.evaluate(x_test,y_test)
print(test_loss)
